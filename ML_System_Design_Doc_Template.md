# ML System Design Doc - [RU]
## Дизайн ML системы - IHT Predictor Script v1.0.0
Предиктор ишемической болезни сердца по минимальному набору биохимических маркеров

### 1. Цели и предпосылки
#### 1.1. Зачем идем в разработку продукта?

- Бизнес-цель:
  - Создать инструмент для раннего выявления пациентов с высоким риском ИБС с помощью минимального набора биохимических маркеров.
- Профит от использования ML:
  - Автоматизация оценки риска для врачей первичного звена.
  - Снижение нагрузки на кардиологов за счет фильтрации низкорисковых пациентов.
- Критерии успеха:
  - Технические:
    - AUC-ROC > 0.85 (означает, что в 85% случаев модель ранжирует случайного пациента с ИБС выше, чем случайного здорового)
    - Recall > 0.8 (минимизация false negative).
  - Бизнес-метрики:
    - Внедрение в 1-2 тестовых клиниках (пилот).
    - Сокращение времени на анализ крови на 50%.

#### 1.2. Бизнес-требования и ограничения

- Бизнес-требования:
  - Минимальная себестоимость (использование open-source стека).
  - Возможность работы через telegram-bot.
- Бизнес-ограничения:
  - Не проводится регуляторный анализ.
- Ожидания от конкретной итерации:
  - Пользователь может подать данные в telegram-bot в описанном формате, получить на выходе лекго-интерпретируемый результат.
- Описание бизнес-процесса пилота:
  - Пользователь готовит данные в описанном формате по одному или нескольким пациентам.
  - Подаёт данные в telegram-bot.
  - Получает легко-интерпретируемый результат по каждому пациенту.
- Способы оценки пилота:
  - Успешный пилот = Система используется врачами в 1-2 клиниках 3+ месяца с показателями:
    - Технические: AUC-ROC не упал на новых данных > 0.02.
    - Бизнес: Врачи сократили время на анализ крови на 30%.
  - Методы оценки:
    - Анкетирование врачей (удобство интерфейса).
    - A/B-тест: сравнение скорости диагностики с/без системы.

#### 1.3. Что входит в скоуп проекта/итерации, что не входит

- В данной итерации выполняется только анализ минимального набора биохимических маркеров крови, возраст, пол и вес пациента:
  - Липидный профиль (оценивает риск атеросклероза — основной причины ИБС):
    - ЛПНП («плохой холестерин») > 3.0 ммоль/л — повышает риск образования бляшек.
    - ЛПВП («хороший холестерин») < 1.0 ммоль/л у мужчин и < 1.2 ммоль/л у женщин — снижает защиту сосудов.
    - Триглицериды > 1.7 ммоль/л — связаны с метаболическими нарушениями.
    - Липопротеин(а) [Lp(a)] > 30 мг/дл — независимый фактор риска тромбозов.
  - Маркеры воспаления (указывают на атеросклеротическое воспаление):
    - С-реактивный белок (СРБ) > 3 мг/л — высокий риск ИБС.
    - Миелопероксидаза (МРО) > 400 мкм — маркер нестабильности бляшек.
  - Кардиоспецифичные белки (обнаруживаются при повреждении миокарда):
    - Тропонины (I/T) — золотой стандарт диагностики инфаркта. Повышение через 2–6 часов после ишемии, пик — через 12–24 часа.
  - Дополнительные маркеры:
    - NT-proBNP > 125 пг/мл — указывает на сердечную недостаточность как осложнение ИБС.
    - Фибриноген > 300 мг/дл — связан с риском тромбозов.
    - Глюкоза и HbA1c — диабет увеличивает риск ИБС в 2–4 раза.
- Не анализируются другие виды скриннинга, таких как ЭКГ, УЗИ и прочее.
- Решение должно легко развёртываться, быть расширяемым.

#### 1.4. Предпосылки решения  

- В России самая высокая смертность от ишемической болезни сердца (20.8% всех смертей). Предоставление инструмента автоматизации анализа риска ИБС снизит риск ошибки врача и повысит его эффективность.
- Гранулярность модели:
  - Диагностический уровень:
    - Вероятность болезни
    - Стадии заболевания
    - Рекомендации
  - Детализация данных:
    - Средняя (анализ биохимических маркеров, возраст, пол, вес)
  - Частота прогнозирования:
    - Разовое (оценка при загрузке данных)

### 2. Методология

#### 2.1. Постановка задачи

Требуется выполнить бинарную классификацию и вернуть на выходе вероятность принадлежности к классу (риск ИБС).

**Выбор модели:**

- Алгоритм: Gradient Boosting (XGBoost/LightGBM)
- Причины:
  - Лучше обрабатывает смешанные типы признаков (бинарные + непрерывные) 
  - Автоматически учитывает взаимодействия (например, ЛПНП × СРБ).
  - Поддержка ранней остановки для избежания переобучения.

> **Описание алгоритма:**
>
> - Обучение:
>   - Последовательно строит деревья, где каждое новое дерево исправляет ошибки предыдущего.
>   - Оптимизирует бинарную логистическую функцию потерь (для классификации).
> - Прогноз:
>   - Возвращает вероятность принадлежности к классу 1 (риск ИБС) — например, 0.78 (78%).
>   - Пороговая обработка (обычно 0.5).

#### 2.2. Блок-схема решения

Блок-схема:
- A[Ввод данных] --> B[Telegram-бот/Консоль]  
- B --> C{Тип данных?}  
  - C -->|CSV| D[Парсинг + проверка столбцов]  
  - C -->|Ручной ввод| E[Конвертация в DataFrame]  
- D & E --> F[Расчет ИМТ, категоризация маркеров]  
- F --> G[Предсказание модели]  
- G --> H[Формирование отчета]  
- H --> I[Вывод риска + рекомендации]

graph TD  
    A[Ввод данных] --> B[Telegram-бот/Консоль]  
    B --> C{Тип данных?}  
    C -->|CSV| D[Парсинг + проверка столбцов]  
    C -->|Ручной ввод| E[Конвертация в DataFrame]  
    D & E --> F[Расчет ИМТ, категоризация маркеров]  
    F --> G[Предсказание модели]  
    G --> H[Формирование отчета]  
    H --> I[Вывод риска + рекомендации]  

> **Пример ответа:**
>
> - Риск ИБС: 68% (критический).  
> - Основные факторы:  
>   1. Тропонин I: 0.15 нг/мл (+25%)  
>   2. ЛПНП: 4.2 ммоль/л (+18%)  
>   3. Lp(a): 50 мг/дл (+12%)  
> - Рекомендации:  
>   - Срочная консультация кардиолога.  
>   - Контроль ЛПНП (цель < 1.8 ммоль/л).

#### 2.3. Этапы решения задачи

##### 2.3.1. Этап 1. Подготовка данных

Для обучения модели будем использовать 3 типа данных:

| Тип данных | Источники | Преимущества | Недостатки
| ------------- | ------------- | ------------- | ------------- |
| Клинические исследования | [Framingham Heart Study](https://biolincc.nhlbi.nih.gov/studies/framcohort), [NHANES](https://wwwn.cdc.gov/nchs/nhanes) | Стандартизированные данные, включают ключевые маркеры | Ограниченный набор новых биомаркеров (нет MPO, Lp(a))
| Госпитальные данные | [MIMIC-IV](https://mimic-iv.mit.edu) | Реальные данные пациентов, есть тропонины | Требует сложной предобработки
| Синтетические данные | Генерация через sdv.tabular.CTGAN на основе реальных распределений | Быстрое прототипирование | Риск артефактов
|

**Стратегия:**

- Базовый набор: Framingham + NHANES (липиды, возраст, пол, глюкоза).
- Расширенный набор: MIMIC-IV (тропонины, NT-proBNP) + синтетические Lp(a)/MPO.

**Целевая переменная (Target):**

- Наличие или риск ишемической болезни сердца (ИБС).
- Формат — Бинарная классификация:
  - 1 — высокий риск/наличие ИБС (например, по диагнозу или шкале SCORE ≥ 5%).
  - 0 — низкий риск/отсутствие ИБС.

**Признаки (Features) и их роль в модели:**

| Категория | Конкретные признаки | Медицинское обоснование | Тип данных
| ------------- | ------------- | ------------- | -------------
| Липидный профиль | ЛПНП, ЛПВП, Триглицериды, Lp(a) | Основные маркеры атеросклероза | Числовой
| Воспаление | СРБ, Миелопероксидаза (MPO) | Воспаление бляшек → риск разрыва | Числовой
| Кардиомаркеры | Тропонин I/T, NT-proBNP | Повреждение миокарда и сердечная недостаточность | Числовой
| Гликемия | Глюкоза, HbA1c | Связь диабета и ИБС | Числовой
| Гемостаз | Фибриноген | Риск тромбозов | Числовой
| Антропометрия | Возраст, Пол (♂=1, ♀=0), ИМТ | Немодифицируемые факторы риска | Числовой/Категориальный
|

**Подготовка и валидация данных:**

- Сбор и объединение
- Очистка (удаление пропусков, обработка выбросов)
- Feature Engineering
- Нормализация
- Валидация качества данных:
  - Полнота: > 80% заполнения для ключевых маркеров.
  - Баланс классов: Доля пациентов с ИБС ≥ 15% (если меньше — oversampling).
- Генерация синтетических данных для редких маркеров (Lp(a), MPO).
- Разделение данных
- Документирование

**Проблемы и решения:**

| Проблема | Решение
| ------------- | -------------
| Нехватка тропонинов | Использовать MIMIC-IV + синтетические данные
| Разные единицы измерения | Конвертация в стандартные (ммоль/л, нг/мл)
| Смещение по полу/возрасту | Стратификация при разделении
|

**Результат этапа:**

- Есть ясность в том, что является целевой перменной, а что признаками, какие данные использовать и как их подготавливать c учётом известных проблем.

> Примеры этапов:  
> - Этап 2 - Подготовка прогнозных моделей  
> - Этап 3 - Интерпретация моделей (согл. с заказчиком)  
> - Этап 4 - Интеграция бизнес правил для расчета бизнес-метрик качества модели  
> - Этап 5 - Подготовка инференса модели по итерациям    
> - Этап 6 - Интеграция бизнес правил  
> - Этап 7 - Разработка оптимизатора (выбор оптимальной итерации)  
> - Этап 8 - Подготовка финального отчета для бизнеса  

 *Этапы 2 и далее, помимо подготовки данных.*
 
Описание техники **для каждого этапа** должно включать описание **отдельно для MVP** и **отдельно для бейзлайна**:  

- Описание формирования выборки для обучения, тестирования и валидации. Выбор репрезентативных данных для экспериментов, обучения и подготовки пилота (от бизнес-цели и репрезентативности данных с технической точки зрения) `Data Scientist`    
- Горизонт, гранулярность, частоту необходимого пересчета прогнозных моделей `Data Scientist`   
- Определение целевой переменной, согласованное с бизнесом `Data Scientist`   
- Какие метрики качества используем и почему они связаны с бизнес-результатом, обозначенным `Product Owner` в разделах `1` и `3`. Пример - WAPE <= 50% для > 80% категорий, bias ~ 0. Возможна формулировка в терминах относительно бейзлайна, количественно. Для бейзлайна могут быть свои целевые метрики, а может их вообще не быть (если это обосновано) `Data Scientist`   
- Необходимый результат этапа. Например, необходимым результатом может быть не просто достижение каких-либо метрик качества, а включение в модели определенных факторов (флаг промо для прогноза выручки, др.) `Data Scientist`    
- Какие могут быть риски и что планируем с этим делать. Например, необходимый для модели фактор (флаг промо) окажется незначимым для большинства моделей. Или для 50% моделей будет недостаточно данных для оценки `Data Scientist`    
- Верхнеуровневые принципы и обоснования для: feature engineering, подбора алгоритма решения, техники кросс-валидации, интерпретации результата (если применимо).  
- Предусмотрена ли бизнес-проверка результата этапа и как будет проводиться `Data Scientist` & `Product Owner`  
  
### 3. Подготовка пилота  
  
#### 3.1. Способ оценки пилота  
  
- Краткое описание предполагаемого дизайна и способа оценки пилота `Product Owner`, `Data Scientist` with `AB Group` 
  
#### 3.2. Что считаем успешным пилотом  
  
Формализованные в пилоте метрики оценки успешности `Product Owner`   
  
#### 3.3. Подготовка пилота  
  
- Что можем позволить себе, исходя из ожидаемых затрат на вычисления. Если исходно просчитать сложно, то описываем этап расчетов ожидаемой вычислительной сложности на эксперименте с бейзлайном. И предусматриваем уточнение параметров пилота и установку ограничений по вычислительной сложности моделей. `Data Scientist` 

### 4. Внедрение `для production систем, если требуется`    

> Заполнение раздела 4 требуется не для всех дизайн документов. В некоторых случаях результатом итерации может быть расчет каких-то значений, далее используемых в бизнес-процессе для пилота.  
  
#### 4.1. Архитектура решения   
  
- Блок схема и пояснения: сервисы, назначения, методы API `Data Scientist`  
  
#### 4.2. Описание инфраструктуры и масштабируемости 
  
- Какая инфраструктура выбрана и почему `Data Scientist` 
- Плюсы и минусы выбора `Data Scientist` 
- Почему финальный выбор лучше других альтернатив `Data Scientist` 
  
#### 4.3. Требования к работе системы  
  
- SLA, пропускная способность и задержка `Data Scientist`  
  
#### 4.4. Безопасность системы  
  
- Потенциальная уязвимость системы `Data Scientist`  
  
#### 4.5. Безопасность данных   
  
- Нет ли нарушений GDPR и других законов `Data Scientist`  
  
#### 4.6. Издержки  
  
- Расчетные издержки на работу системы в месяц `Data Scientist`  
  
#### 4.5. Integration points  
  
- Описание взаимодействия между сервисами (методы API и др.) `Data Scientist`  
  
#### 4.6. Риски  
  
- Описание рисков и неопределенностей, которые стоит предусмотреть `Data Scientist`   
  
> ### Материалы для дополнительного погружения в тему  
> - [Шаблон ML System Design Doc [EN] от AWS](https://github.com/eugeneyan/ml-design-docs) и [статья](https://eugeneyan.com/writing/ml-design-docs/) с объяснением каждого раздела  
> - [Верхнеуровневый шаблон ML System Design Doc от Google](https://towardsdatascience.com/the-undeniable-importance-of-design-docs-to-data-scientists-421132561f3c) и [описание общих принципов его заполнения](https://towardsdatascience.com/understanding-design-docs-principles-for-achieving-data-scientists-53e6d5ad6f7e).
> - [ML Design Template](https://www.mle-interviews.com/ml-design-template) от ML Engineering Interviews  
> - Статья [Design Documents for ML Models](https://medium.com/people-ai-engineering/design-documents-for-ml-models-bbcd30402ff7) на Medium. Верхнеуровневые рекомендации по содержанию дизайн-документа и объяснение, зачем он вообще нужен  
> - [Краткий Canvas для ML-проекта от Made with ML](https://madewithml.com/courses/mlops/design/#timeline). Подходит для верхнеуровневого описания идеи, чтобы понять, имеет ли смысл идти дальше.  
